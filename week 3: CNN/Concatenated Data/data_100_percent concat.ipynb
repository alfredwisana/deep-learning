{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfredwisana/deep-learning/blob/main/week%203%3A%20CNN/data_100_percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsiXpTJ5-0Zz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjCeCVGh-0Z1"
      },
      "source": [
        "READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc7PacLw-0Z2"
      },
      "outputs": [],
      "source": [
        "(train_data, test_data), ds_info = tfds.load(name=\"emnist/digits\",\n",
        "                                             split=[\"train\", \"test\"],\n",
        "                                             shuffle_files=True,\n",
        "                                             as_supervised=True, # Data gets returned in tuple format (data, label)\n",
        "                                             with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data = train_data.concatenate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoKMzM5oyk-p"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for image, label in tfds.as_numpy(train_data):\n",
        "  dataset.append({\n",
        "      'image' : image,\n",
        "      'label' : int(label)\n",
        "  })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1C_RkdUyk-p"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qKeqtBmyk-p"
      },
      "outputs": [],
      "source": [
        "with open('dataset_concat.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XReRjoLlyk-q"
      },
      "outputs": [],
      "source": [
        "with open('dataset.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R9oZgoJMyk-q"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "for i in range(len(dataset)):\n",
        "  X.append(tf.cast(dataset[i]['image'], tf.float32) / 255)\n",
        "  Y.append(tf.one_hot(dataset[i]['label'], depth=10))\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Sd3cgDfyk-r"
      },
      "outputs": [],
      "source": [
        "with open('datax_concat.pkl','wb') as f:\n",
        "    pickle.dump(X, f)\n",
        "\n",
        "with open('datay_concat.pkl','wb') as f:\n",
        "    pickle.dump(Y, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fz3Vdv0dyk-r"
      },
      "outputs": [],
      "source": [
        "with open('datax.pkl','rb') as f:\n",
        "    X = pickle.load(f)\n",
        "with open('datay.pkl','rb') as f:\n",
        "    Y = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoEnntAdyk-r"
      },
      "outputs": [],
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('x_train.pkl','wb') as f:\n",
        "    pickle.dump(Xtrain, f)\n",
        "\n",
        "with open('y_train.pkl','wb') as f:\n",
        "    pickle.dump(Ytrain, f)\n",
        "\n",
        "with open('x_test.pkl','wb') as f:\n",
        "    pickle.dump(Xtest, f)\n",
        "\n",
        "with open('y_test.pkl','wb') as f:\n",
        "    pickle.dump(Ytest, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('x_train.pkl','rb') as f:\n",
        "    Xtrain = pickle.load(f)\n",
        "with open('y_train.pkl','rb') as f:\n",
        "    Ytrain = pickle.load(f)\n",
        "\n",
        "with open('x_test.pkl','rb') as f:\n",
        "    Xtest = pickle.load(f)\n",
        "with open('y_test.pkl','rb') as f:\n",
        "    Ytest = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUpvcjHj-0Z2"
      },
      "source": [
        "Data Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecS3FmRByk-t"
      },
      "outputs": [],
      "source": [
        "# Plot the validation and training curves separately\n",
        "def plot_loss_curves(history):\n",
        "    \"\"\"\n",
        "    Returns separate loss curves for training and validation metrics\n",
        "    \"\"\"\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    epochs = range(len(history.history['loss'])) # How many epochs\n",
        "\n",
        "\n",
        "    # Plot loss\n",
        "    plt.plot(epochs, loss, label=\"training_loss\")\n",
        "    plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        "    plt.title(\"loss\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        "    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "    plt.title(\"accuracy\")\n",
        "    plt.xlabel(\"epochs\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a89rxN5Z-0Z2"
      },
      "source": [
        "Alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNYv08ES-0Z3",
        "outputId": "71b004bd-fbbf-47fe-8c9b-d1ba1724ab72"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(shape=(28,28,1)),\n",
        "        keras.layers.Conv2D(96, kernel_size=(3,3), strides=(1,1), activation='relu'),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "        keras.layers.Conv2D(256, kernel_size=(5,5), activation='relu',padding='same'),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "        keras.layers.Conv2D(384, kernel_size=(3,3), activation='relu',padding='same'),\n",
        "        keras.layers.Conv2D(384, kernel_size=(3,3), activation='relu',padding='same'),\n",
        "        keras.layers.Conv2D(256, kernel_size=(3,3), activation='relu',padding='same'),\n",
        "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(4096, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHv9kzcDyk-u"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_ligSMTyk-u",
        "outputId": "8bfca67b-307a-4adf-efec-3aefc95d0aa0"
      },
      "outputs": [],
      "source": [
        "history_alexnet = model.fit(Xtrain, Ytrain,epochs=10, batch_size=16, validation_data=(Xtest,Ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZQqhjuVyk-v"
      },
      "outputs": [],
      "source": [
        "with open('history_alexnet_concat.pkl', 'wb') as f:\n",
        "    pickle.dump(history_alexnet, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SS5FjyXSyk-v"
      },
      "outputs": [],
      "source": [
        "with open('data_100persen/history_alexnet.pkl', 'rb') as f:\n",
        "    history_alexnet = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejvwzx7myk-v",
        "outputId": "d0be45d9-ec29-4dc5-a15e-e82a4a353fcf"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_alexnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsDNeL6g-0Z3"
      },
      "source": [
        "LENET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HRjhDsi-0Z3",
        "outputId": "3f328bc1-7d4c-44f0-c26a-158191c93798"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential(\n",
        "    [\n",
        "      keras.layers.Input((28,28,1)),\n",
        "      keras.layers.Conv2D(6, kernel_size=(5,5), activation='sigmoid'),\n",
        "      keras.layers.MaxPool2D(pool_size=2, strides=(2,2)),\n",
        "      keras.layers.Conv2D(16, kernel_size=(5,5), activation='sigmoid'),\n",
        "      keras.layers.MaxPool2D(pool_size=2, strides=(2,2)),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(120, activation='sigmoid'),\n",
        "      keras.layers.Dense(84, activation='sigmoid'),\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPxdPhiKyk-v"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pMT-C2_yk-w",
        "outputId": "dbf48fad-6c57-47ac-c486-3fc4c29198f8"
      },
      "outputs": [],
      "source": [
        "history_lenet = model.fit(Xtrain, Ytrain,epochs=10, batch_size=16, validation_data=(Xtest,Ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPYOkqT7yk-w"
      },
      "outputs": [],
      "source": [
        "with open('history_lenet_concat.pkl', 'wb') as f:\n",
        "    pickle.dump(history_lenet, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtxZ6dg_yk-w"
      },
      "outputs": [],
      "source": [
        "with open('history_lenet.pkl', 'rb') as f:\n",
        "    history_lenet = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRxrIr2Eyk-w",
        "outputId": "12380661-f3d0-4b6b-cb00-8d2e2ac483d1"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history_lenet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chDT0O8Z-0Z3"
      },
      "source": [
        "CUSTOM MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYTlOBrUyk-w"
      },
      "outputs": [],
      "source": [
        "model = keras.models.Sequential(\n",
        "    [\n",
        "      keras.layers.Input((28,28,1)),\n",
        "\n",
        "      keras.layers.Conv2D(6, kernel_size=(5,5), activation='sigmoid'),\n",
        "      keras.layers.Conv2D(12, kernel_size=(5,5), activation='sigmoid', padding='same'),\n",
        "\n",
        "      keras.layers.MaxPool2D(pool_size=2, strides=(2,2)),\n",
        "      keras.layers.Conv2D(16, kernel_size=(5,5), activation='sigmoid', padding='same'),\n",
        "      keras.layers.Conv2D(32, kernel_size=(3,3), activation='sigmoid', padding='same'),\n",
        "      keras.layers.Conv2D(32, kernel_size=(3,3), activation='sigmoid', padding='same'),\n",
        "      keras.layers.MaxPool2D(pool_size=2, strides=(2,2)),\n",
        "\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dense(120, activation='sigmoid'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(84, activation='sigmoid'),\n",
        "\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_custom = model.fit(Xtrain, Ytrain,epochs=10, batch_size=16, validation_data=(Xtest,Ytest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('history_custom.pkl', 'wb') as f:\n",
        "    pickle.dump(history_custom, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('history_lenet.pkl', 'rb') as f:\n",
        "    history_custom = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_loss_curves(history_custom)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Nw5stXyk-w"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
